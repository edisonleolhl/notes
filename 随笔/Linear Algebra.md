## [Essence of Linear Algebra](https://www.bilibili.com/video/av6731067/?p=1)

### 向量（Vector）

- 计算机学生眼里：向量是数字列表

- 物理学生眼里：向量是箭头

- 数学家认为：向量可以表示任何东西，只要满足两个运算关系——数乘（scalar multiplication）与加法

### 线性组合、张成的空间和基（Linear combination、span and base）

- 将每个坐标看成标量，这些标量与基向量数乘后就可以表示所有向量

- 对于二维空间，只需要两个***基向量***——i-hat and j-hat，就可以用它们的线性组合表示整个二维空间所有的向量

  但是如果这两个基向量是同向或者反向的，则没法表示整个二维空间的所有向量

- 为何叫***线性组合***？

  对于二维空间的基向量，如果把其中一个基向量固定，另一个基向量变化，则合向量的末端会落在一条直线上

- 基向量的全部线性组合构成的向量集合称为“***张成的空间***”

- 对于三维空间，两个向量张成的空间是什么？

  根据三点共面，张成的空间是这两个向量所确定的面

- 对于三维空间，三个向量张成的空间是什么？

  如果三个向量不共面，则张成的空间是整个三维空间，这时这三个向量***线性无关（linearly independent）***

  如果三个向量共面，则引入的第三个向量并不会使空间维数增加，因为这三个向量是***线性相关（linearly dependent）***的，第三个向量已经落在了由前两个向量张成的空间里，可以由前两个向量线性表示

- 由此引出基的严格定义（From维基百科）：

  A basis *B* of a [vector space](https://en.wikipedia.org/wiki/Vector_space) *V* over a [field](https://en.wikipedia.org/wiki/Field_(mathematics)) *F* (such as the [real numbers](https://en.wikipedia.org/wiki/Real_numbers) R or the [complex numbers](https://en.wikipedia.org/wiki/Complex_number) C) is a [linearly independent](https://en.wikipedia.org/wiki/Linear_independence) subset of *V* that [spans](https://en.wikipedia.org/wiki/Linear_span) *V*. 

  **向量空间的一个基是张成该空间的一个线性无关V的子集**  

  This means that, a subset B of *V* is a basis if it satisfies the two following conditions:

  - the *linear independence* property:

    for every finite subset {*b*1, ..., *bn*} of B and every *a*1, ..., *an* in **F**, if *a*1*b*1 + ⋅⋅⋅ + *anbn* = 0, then necessarily *a*1 = ⋅⋅⋅ = *an* = 0;

  - the *spanning* property:

    for every (vector) *v* in *V*, it is possible to choose *v*1, ..., *vn* in **F** and *b*1, ..., *bn* in B such that *v* = *v*1*b*1 + ⋅⋅⋅ + *vnbn*.

  The [scalars](https://en.wikipedia.org/wiki/Scalar_(mathematics)) *vi* are called the coordinates of the vector *v* with respect to the basis *B*, and by the first property they are uniquely determined.

  标量vi是向量v关于基B的坐标，根据第一个性质，vi是唯一确定的

### **矩阵与线性变换（Matrices and Linear transformations）**

- 线性变换其实只是函数（function）的另一种说法

  用“线性变换”而不是“线性函数”，是为了表示“移动”的概念，因为线性变换可以让向量移动到另一个位置

- 线性变换

  （二维平面）直线仍然是直线、保持原点不动、保持网格线平行且等距

- 矩阵的积

  对应的两个线性变换相继作用

  从右向左读，就像函数一样

  Matrix: A×B×X，X先与B相乘，再与A相乘 / X先做关于B的线性变化，再做关于A的线性变换

  Function: f(g(x))，g是关于变量x的函数，而f是关于g的函数

- 矩阵不具有交换律（Commutative property）：

  A×B≠B×A

  但是从右往左读的，具有结合律（Associative property）：

  (A×B)×C=A×(B×C)

### 行列式（Determinant）

- 线性变换有时会使空间延伸，有时会压缩空间，所以需要探讨空间（面积/体积/...）变化了多少倍

  考虑如下矩阵

  ```
  1 0
  0 1
  ```

- 线性变化的行列式（The determinant of a transformation）

  行列式就是用来表示线性变换对空间的扩张/压缩程度的度量

  记作det(A)

- 但是行列式有负值，怎么理解?

  定向（Orientation）如果不变，则为正值，如果变化，行列式为负值，其绝对值是扩张/压缩的倍数

  对于二维空间，i-hat本来在j-hat的顺时针90度方向，线性变换后，i-hat-landed在j-hat-landed的逆时针方向，这时定向（Orientation）改变了，所以行列式取负值

  对于三维空间，i-hat、j-hat、z-hat的方向符合右手定则，如果线性变换后仍满足右手定则，则定向（Orientation）不变，行列式为正值

### 逆矩阵、列空间、秩、零空间（Inverse matrices, Column space, Rank, Null space）

- 计算方法在Essence of Linear Algebra中不会重点讲解，可以自行搜索高斯消元法和行阶梯形

- 考虑一个线性方程组（linear system of equations ）：

  AX=Y

  对于向量X^T=(x1, x2, x3, ..., xn)，乘以系数矩阵A后得到向量Y^T

  别忘了矩阵的乘法就是对向量进行线性变换，所以通过线性变换（A）可以把X“变换”到Y

  那么如何把Y“变换”到X？这就相当于**线性变换的逆变换**：

  X=A^(-1)×Y

- 单位矩阵

  两个线性变换相继作用相当于矩阵的乘法，所以一个矩阵的逆（矩阵）乘以这个矩阵本身，相当于“什么也不做”

  这时把它们的积称为**单位矩阵**：

  A^(-1)×A=E

- 逆矩阵恒存在吗？

  显然不是，当det(A)=0时，线性变换把原空间压缩（降维）了，没法把压缩的空间解压缩

  对于二维：如果det(A)=0，则线性变换把平面压缩成了一条线（或一个点），你无法将一条线“解压缩”为一个平面，因为平面是无数线的集合，没法用这一条线去表示这无数的、方向各异的线，线性变换使得二维平面的度量——面积压缩为0

  对于三维：如果det(A)=0，则线性变换把三维空间压缩成了一个面（或一条线甚至一个点），你也无法将一个面“解压缩”为一个三维空间，因为线性变换使得三维空间的度量——体积压缩为0

- 行列式为0（即det(A)=0）时，线性方程组一定无解？

  不一定，有可能Y正好落在线性变换压缩后的空间中

  对于二维：det(A)=0，线性变换把空间从平面压缩为线，有可能Y正好在这条线上，所以有解

  对于三维：det(A)=0，线性变换把空间从三维空间压缩为面，有可能Y正好在这个面上，所以有解

- 对于同维向量空间，不同的det(A)=0，产生线性变换的效果一样吗？

  不一样，比如对于三维空间，有可能线性变换使三维空间压缩为二维空间（即平面），也有可能压缩得更厉害，成了一维空间（即直线）

- 如何度量呢？——————**用秩来度量**

  如果线性变换使所有向量都落在同一条线上，则说这个线性变换的秩为1

  如果线性变换使所有向量都落在同一平面上，则说这个线性变换的秩为2

  如果线性变换使所有向量都落在同一三维空间上，则说这个线性变换的秩为3

  ...

  所以，**秩（Rank）代表着线性变换后空间的维数（Number of dimensions in the output）**

  如果det(A)≠0：

  对于2x2矩阵，线性变换最多只能从平面变换到平面，所以最大的秩为2

  对于3x3矩阵，线性变换最多只能从空间变换到空间，所以最大的秩为3

  如果det(A)=0：

  线性变换一定会使原空间**降维**

- 列空间：所有可能的输出向量构成的集合

  线性变换使基向量发生变换，变换后的基向量张成的空间就是所有可能的变换结果

  **列空间就是矩阵的列所张成的空间**

  于是，**秩就是列空间的维数**

  > 列空间可以告诉我们线性方程组何时有解何时无解

- 当秩达到最大值时，意味着秩与列数相等，这时成为满秩（Full rank）

- 零空间（Null space）/ 核（Kernel）

  零向量一定在列空间中，因为线性变换必须保持原点不变

  对于满秩变换，唯一能在变换后落在原点的就是零向量本身

  对于非满秩变换，会有一系列向量在变换后成为零向量

  - 对于平面，非满秩变换，意味着det(A)=0，变换后成为一条直线，在原来的平面一定存在一条直线，该直线上的所有向量变换后的向量为零向量（用动画想象一下如何从平面压缩到直线就知道了）
  - 对于三维空间，非满秩变换，意味着det(A)=0，变换后成为一个平面（或一条直线），在原来的三维空间中一定存在一个平面（或一条直线），该平面（或一条直线）上的所有向量变换后的向量为零向量

  **这些变换后为零向量的向量，称为矩阵的零空间或核**

  > 对于线性方程组，如果Y为零向量，则系数矩阵A的零空间就是这个线性方程组的所有可行解，或者说这个线性方程组的所有可行解构成了系数矩阵A的零空间

### 非方阵

- 3x2矩阵的几何意义就是把二维空间映射到三维空间上

  矩阵有两列，表明输入空间有两个基向量

  矩阵有三行，表明每一个基向量在变换后都用三个独立的坐标来描述

  其列空间的维数为2，如果满秩的话也为2

- 2x3矩阵的几何意义就是把三维空间映射到二维空间上

  矩阵有三列，表明输入空间有三个基向量

  矩阵有二行，表明每一个基向量在变换后都用二个独立的坐标来描述

  其列空间的维数为2，如果满秩的话也为2

### 点积与对偶性（Dot product and duality）

- 两个向量的点积，就是对应坐标的积之和

  两个向量的方向在同一侧时，点积为正

  两个向量的方向在相反侧时，点积为负

  两个向量的方向垂直时，点积为0

- 点积在几何上的解释就是一个向量在另一个向量方向上的投影（projection），再乘以另一个向量，得到一个标量（scalar）

- 如何理解点积具有交换性呢？

  假设两个向量共线，那么投影就是本身，这时就是普通的乘法，具有交换性：

  |v||w|=|w||v|

  假设两个向量不共线，再假设两个向量是同等长度，那么可以找到一条对称线，无论是哪个向量“主动”投影过去，点积肯定是相同的：

  v·v=v·v

  假定其中一个向量缩放了n倍，点积的结果也是原来的n倍：

  (nv)·v=n(v·v)

  因为n可取任意值，推广到任意长度的向量，于是点积具有交换性：

  v·w=w·v

- 为何对应坐标的积之和可以和投影联系起来?

  回想矩阵的知识，1x2矩阵（线性变换）乘以2x1矩阵（某向量有两个坐标），得到1x1矩阵，也就是标量，这不就是向量的点积吗？

  两个向量点积，就是把其中一个向量转化为线性变换

  很巧妙地用到了对偶性的知识，笔记不好做，看视频吧

- 一个向量的对偶是由它定义的线性变换
- 一个多维空间到一维空间的线性变换的对偶是多维空间中某个特定向量

- **向量不仅仅是空间中的箭头，还是线性变换的物质载体**

### 叉积（Cross product）

- 两个向量的叉积可以生成另一个向量，记作：

  v×w=p

  |p|=det(k;v;w)=平行四边形，其中v、w是列向量的各位坐标（不带方向），k为一组基向量（带方向）

  p的方向垂直于平行四边形，用右手定则确定

- 叉积何时为正，何时为负？

  巧妙记忆：xoy直角坐标系，v为x，w为y，这时叉积为正v×w>0；否则叉积为负v×w<0

  于是有，v×w=-w×v
