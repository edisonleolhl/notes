# 数据结构与算法

> 本文包括：
1. 算法概念
1. 时间复杂度
1. 大 O 记法
1. 数据结构概念
1. Python 内置类型的效率

## 算法的概念

- 算法是计算机处理信息的本质，因为计算机程序本质上是一个算法来告诉计算机确切的步骤来执行一个指定的任务。一般地，当算法在处理信息时，会从输入设备或数据的存储地址读取数据，把结果写入输出设备或某个存储地址供以后再调用。

- 算法是独立存在的一种解决问题的方法和思想。

- 对于算法而言，实现的语言并不重要，重要的是思想。

- 算法可以有不同的语言描述实现版本（如 C 描述、C++ 描述、Python 描述等），我们现在是在用 Python 语言进行描述实现。

## 算法的五大特性

- 输入: 算法具有0个或多个输入
- 输出: 算法至少有1个或多个输出
- 有穷性: 算法在有限的步骤之后会自动结束而不会无限循环，并且每一个步骤可以在可接受的时间内完成
- 确定性：算法中的每一步都有确定的含义，不会出现二义性
- 可行性：算法的每一步都是可行的，也就是说每一步都能够执行有限的次数完成

## 执行时间反应算法效率

- 对于同一问题，我们给出了两种解决算法，在两种算法的实现中，我们对程序执行的时间进行了测算，发现两段程序执行的时间相差悬殊（214.583347秒相比于0.182897秒），由此我们可以得出结论：实现算法程序的执行时间可以反应出算法的效率，即算法的优劣。

## 单靠时间值绝对可信吗？

- 假设我们将第二次尝试的算法程序运行在一台配置古老性能低下的计算机中，情况会如何？很可能运行的时间并不会比在我们的电脑中运行算法一的214.583347秒快多少。

### 单纯依靠运行的时间来比较算法的优劣并不一定是客观准确的！

- 程序的运行离不开计算机环境（包括硬件和操作系统），这些客观原因会影响程序运行的速度并反应在程序的执行时间上。那么如何才能客观的评判一个算法的优劣呢？

## 时间复杂度与“大O记法”

- 我们假定计算机执行算法每一个基本操作的时间是固定的一个时间单位，那么有多少个基本操作就代表会花费多少时间单位。算然对于不同的机器环境而言，确切的单位时间是不同的，但是对于算法进行多少个基本操作（即花费多少时间单位）在规模数量级上却是相同的，由此可以忽略机器环境的影响而客观的反应算法的时间效率。

- 《算法导论》中定义了三种函数，O, Ω, θ

  - 确定一个函数渐近上界：Ο 符号
  - 渐近下界：Ω 符号
  - 渐近紧确界：θ 符号

  ![](http://images2015.cnblogs.com/blog/431521/201509/431521-20150915161017039-979340488.png)

- 大部分情况下，对于算法的时间效率，我们可以用“大O记法”来表示。

- “大O记法”：对于单调的整数函数f，如果存在一个整数函数g和实常数c>0，使得对于充分大的n总有f(n)<=c*g(n)，就说函数g是f的一个渐近函数（忽略常数），记为f(n)=O(g(n))。也就是说，在趋向无穷的极限意义下，函数f的增长速度受到函数g的约束，亦即函数f与函数g的特征相似。

- 时间复杂度：假设存在函数g，使得算法A处理规模为n的问题示例所用时间为T(n)=O(g(n))，则称O(g(n))为算法A的渐近时间复杂度，简称时间复杂度，记为T(n)

## 如何理解“大O记法”

- 对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些是分析算法效率的主要部分。

- 而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为3n^2和100n^2属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为n^2级。

## 最坏时间复杂度

- 分析算法时，存在几种可能的考虑：

  - 算法完成工作最少需要多少基本操作，即最优时间复杂度
  - 算法完成工作最多需要多少基本操作，即最坏时间复杂度
  - 算法完成工作平均需要多少基本操作，即平均时间复杂度

- 对于最优时间复杂度，其价值不大，因为它没有提供什么有用信息，其反映的只是最乐观最理想的情况，没有参考价值。

- 对于最坏时间复杂度，提供了一种保证，表明算法在此种程度的基本操作中一定能完成工作。

- 对于平均时间复杂度，是对算法的一个全面评价，因此它完整全面的反映了这个算法的性质。但另一方面，这种衡量并没有保证，不是每个计算都能在这个基本操作内完成。而且，对于平均情况的计算，也会因为应用算法的实例分布可能并不均匀而难以计算。

- 因此，我们主要关注算法的最坏情况，亦即最坏时间复杂度。

  > 《算法导论》上有三点理由：
  > 1. 知道了算法在任何输入下运行时间的上界，从而确保算法绝不需要更长的时间。
  > 1. 对某些算法，最坏情况经常出现。
  > 1. 平均情况往往和最坏情况大致一样差。

## 时间复杂度的几条基本计算规则

- 基本操作，即只有常数项，认为其时间复杂度为O(1)
- 顺序结构，时间复杂度按加法进行计算
- 循环结构，时间复杂度按乘法进行计算
- 分支结构，时间复杂度取最大值
- 判断一个算法的效率时，往往只需要关注操作数量的最高次项，其它次要项和常数项可以忽略
- 在没有特殊说明时，我们所分析的算法的时间复杂度都是指最坏时间复杂度

## 常见时间复杂度

|执行次数函数举例|阶|非正式术语|
|-|-|-|
|12|O(1)|常数阶|
|2n+3|O(n)|线性阶|
|3n2+2n+1|O(n2)|平方阶|
|5log2n+20|O(logn)|对数阶|
|2n+3nlog2n+19|O(nlogn)|nlogn阶|
|6n3+2n2+3n+4|O(n3)|立方阶|
|2n|O(2n)|指数阶|

>注意，经常将log2n（以2为底的对数）简写成logn

---

## 什么是数据结构？

- 我们如何用Python中的类型来保存一个班的学生信息？ 如果想要快速的通过学生姓名获取其信息呢？

- 实际上当我们在思考这个问题的时候，我们已经用到了数据结构。列表和字典都可以存储一个班的学生信息，但是想要在列表中获取一名同学的信息时，就要遍历这个列表，其时间复杂度为 O(n)，而使用字典存储时，可将学生姓名作为字典的键，学生信息作为值，进而查询时不需要遍历便可快速获取到学生信息，其时间复杂度为 O(1)。

- 我们为了解决问题，需要将数据保存下来，然后根据数据的存储方式来设计算法实现进行处理，那么数据的存储方式不同就会导致需要不同的算法进行处理。我们希望算法解决问题的效率越快越好，于是我们就需要考虑数据究竟如何保存的问题，这就是数据结构。

- 在上面的问题中我们可以选择 Python 中的列表或字典来存储学生信息。列表和字典就是 Python 内建帮我们封装好的两种数据结构。

## 数据结构相关概念

- 数据是一个抽象的概念，将其进行分类后得到程序设计语言中的基本类型。如：int，float，char 等。数据元素之间不是独立的，存在特定的关系，这些关系便是结构。数据结构指数据对象中数据元素之间的关系。

- Python 给我们提供了很多现成的数据结构类型，这些系统自己定义好的，不需要我们自己去定义的数据结构叫做 Python 的内置数据结构，比如列表、元组、字典。而有些数据组织方式，Python 系统里面没有直接定义，需要我们自己去定义实现这些数据的组织方式，这些数据组织方式称之为 Python 的扩展数据结构，比如栈，队列等。

## 算法与数据结构的区别

- 数据结构只是静态的描述了数据元素之间的关系。

- 高效的程序需要在数据结构的基础上设计和选择算法。

### 程序 = 数据结构 + 算法

### 总结：算法是为了解决实际问题而设计的，数据结构是算法需要处理的问题载体

## 抽象数据类型(Abstract Data Type)

- 抽象数据类型(ADT)的含义是指一个数学模型以及定义在此数学模型上的一组操作。即把数据类型和数据类型上的运算捆在一起，进行封装。引入抽象数据类型的目的是把数据类型的表示和数据类型上运算的实现与这些数据类型和运算在程序中的引用隔开，使它们相互独立。

- 最常用的数据运算有五种：

  - 插入
  - 删除
  - 修改
  - 查找
  - 排序

## Python 内置类型性能分析

### timeit 模块

- timeit 模块可以用来测试一小段 Python 代码的执行速度。

      class timeit.Timer(stmt='pass', setup='pass', timer=<timer function>)

  - Timer 是测量小段代码执行速度的类。

  - stmt 参数是要测试的代码语句（statment）；

  - setup 参数是运行代码时需要的设置；

  - time r参数是一个定时器函数，与平台有关。

- Timer 类中测试语句执行速度的对象方法。number 参数是测试代码时的测试次数，默认为 1000000 次。方法返回执行代码的平均耗时，一个 float 类型的秒数。

      timeit.Timer.timeit(number=1000000)

### list 性能测试

- 代码

      from timeit import Timer


      def test1():
          l = []
          for i in range(1000):
              l = l + [i]


      def test2():
          l = []
          for i in range(1000):
              l.append(i)


      def test3():
          l = [i for i in range(1000)]


      def test4():
          l = list(range(1000))


      t1 = Timer("test1()", "from __main__ import test1")
      print("concat ", t1.timeit(number=1000), "seconds")

      t2 = Timer("test2()", "from __main__ import test2")
      print("append ", t2.timeit(number=1000), "seconds")

      t3 = Timer("test3()", "from __main__ import test3")
      print("comprehension ", t3.timeit(number=1000), "seconds")

      t4 = Timer("test4()", "from __main__ import test4")
      print("list range ", t4.timeit(number=1000), "seconds")

- 输出

      concat  1.5475910836515439 seconds
      append  0.08007548530159792 seconds
      comprehension  0.03215566085239119 seconds
      list range  0.01430455445519141 seconds

- 结论

  可以看到，花费时间从多到少，所以编程时尽量用 list(range(x)) 这种方法创建列表

- list 各操作的效率：

  ![2017911-list操作](http://ooy7h5h7x.bkt.clouddn.com/blog/image/2017911-list操作.png)

- dict 各操作的效率：

  ![2017911-dict操作](http://ooy7h5h7x.bkt.clouddn.com/blog/image/2017911-dict操作.png)