# 数据结构与算法之美

- 数据结构和算法是相辅相成的。**数据结构是为算法服务的，算法要作用在特定的数据结构之上**

- 想要学习数据结构与算法，**首先要掌握一个数据结构与算法中最重要的概念——复杂度分析。**
- 王争总结的最常用、最基础的20个数据结构与算法
  - 10个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树；
  - 10个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

## 复杂度分析

- 规律：**所有代码的执行时间T(n)与每行代码的执行次数f(n)成正比**。
- **大O时间复杂度表示法**：T(n)=O(f(n))
  - T(n)我们已经讲过了，它表示代码执行的时间；
  - n表示数据规模的大小；
  - f(n)表示每行代码执行的次数总和。
  - 公式中的O，表示代码的执行时间T(n)与f(n)表达式成正比。

- 大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。大O表示法通常会忽略掉公式中的常量、低阶、系数

- **加法法则：总复杂度等于量级最大的那段代码的复杂度**

- **乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积**

- **多项式量级**和**非多项式量级**。其中，非多项式量级只有两个：O(2n)和O(n!)。

  > 我们把时间复杂度为非多项式量级的算法问题叫作NP（Non-Deterministic Polynomial，非确定多项式）问题。

- 常见时间复杂度

  - O(1)：**一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)**

  - O(log2(n))：O(log3(n))也可以转换为O(log2(n))，因为log3(n)就等于log3(2) * log2(n)，log3(2)是常数系数，可以省略

    ```c++
    // 示例
    i=1;
     while (i <= n)  {
       i = i * 3;
     }
    ```

  - O(n*log2(n))：乘法法则，加一层n的嵌套，也很常见，比如归并排序、快速排序的时间复杂度都是O(nlogn)

  - **O(m+n)、O(m\*n)**：**由两个数据的规模**来决定，m和n是表示两个数据规模。我们无法事先评估m和n谁的量级大

- **最好情况时间复杂度**（best case time complexity）、**最坏情况时间复杂度**（worst case time complexity）
- **平均情况时间复杂度**（average case time complexity）：可能需要概率论的知识，但在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况，只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。
- **均摊时间复杂度**（amortized time complexity）：比平均时间复杂度更特殊，**摊还分析法**：每一次O(n)的插入操作，都会跟着n-1次O(1)的插入操作，所以把耗时多的那次操作均摊到接下来的n-1次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是O(1)

## 数组

- **数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据**

  > 除了数组，链表、队列、栈等也是线性表结构

- 高级语言一般提供了容器了代替数组，但数组在以下场景还是有用武之地的：
  - 1.Java ArrayList无法存储基本类型，比如int、long，需要封装为Integer、Long类，而Autoboxing、Unboxing则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
  - 2.如果数据大小事先已知，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以直接使用数组。
  - 3.还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如Object[][] array；而用容器的话则需要这样定义：`ArrayList<ArrayList > array

- 对于业务开发，直接使用容器就足够了，但是如果是底层开发，需要极致性能，数组会更优，当然debug难度也会更大

- 为什么数组要从0开始编号？

  - “下标”最确切的定义应该是“偏移（offset）”。如果用a来表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址

    > ```c
    > // a[k]的内存地址计算公式
    > a[k]_address = base_address + k * type_size
    > // 二维数组的内存地址计算公式
    > a[x][y]_address = base_address + (y * x_array_length(X轴长度) + x) * data_type_size
    > 
    > ```

  - 后面出现的编程语言效仿C语言，也都用0作为下表了，但是Matlab是从1开始的，Python甚至还支持负数下标

## 链表

- LinkedHashMap就是使用的双向链表
- **用空间换时间**，双向链表虽然比单链表每个节点都多了一个前驱指针，但是查找与删除操作更加灵活
- 链表vs数组
  - 数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对CPU缓存不友好，没办法有效预读。
  - 数组的缺点是大小固定，一经声明就要占用整块连续内存空间，链表天然就支持扩容
  - 如果你的代码对内存的使用非常苛刻，那数组就更适合你，因为链表需要额外的空间存储指针

- 缓存淘汰算法，常见的策略有三种：先进先出策略FIFO（First In，First Out）、最少使用策略LFU（Least Frequently Used）、最近最少使用策略LRU（Least Recently Used）

- 有序单链表就可以实现LRU，当有一个新的数据被访问时，我们从链表头开始顺序遍历链表（因为这个操作，所以时间复杂度为O(n)）。

  1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。

  2. 如果此数据没有在缓存链表中，又可以分为两种情况：

     - 如果此时缓存未满，则将此结点直接插入到链表的头部；

     - 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

  3. 引入**散列表**（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到O(1)

- 如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？

  1、通过快慢指针定位中间节点

  2、对后半部分链表逆序

  3、前后链表对比，判断是否为回文串

  4、恢复后半部分链表顺序

  时间复杂度O(n)、空间复杂度O(1)

- 写链表代码的技巧

  - 理解指针或引用的含义，p->next=q，p结点中的next指针存储了q结点的内存地址。

  - 警惕指针丢失和内存泄漏，**插入结点时，一定要注意操作的顺序**，**删除链表结点时，也一定要记得手动释放内存空间**，

  - 利用哨兵简化实现难度，**针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理**，在任何时候，不管链表是不是空，head指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫**带头链表**。相反，没有哨兵结点的链表就叫作**不带头链表**。

  - 重点留意边界条件处理

    - 如果链表为空时，代码是否能正常工作？

    - 如果链表只包含一个结点时，代码是否能正常工作？

    - 如果链表只包含两个结点时，代码是否能正常工作？

    - 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

  - 举例画图，辅助思考

  - 多写多练，没有捷径

    - 单链表反转

    - 链表中环的检测

    - 两个有序的链表合并

    - 删除链表倒数第n个结点

    - 求链表的中间结点

## 栈

- 栈只支持两个基本操作：**入栈push()和出栈pop()**
- 从功能上来说，数组或链表确实可以替代栈，但是数组或链表暴露了太多操作接口，操作比较不可控，容易出错
- 复习一下均摊分析法，动态扩容的数组/栈，k-1次插入操作都是O(1)，然后来一次顺序搬迁需要O(n)，但是均摊到前面k-1次O(1)的操作上，所以摊还分析时间复杂度仍然是O(1)

- 应用

  - 函数栈

  - 表达式求值，一个栈保存操作数，一个栈保存运算符

    - 如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；
    - 如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取2个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

    ![image-20220117002103552](https://tva1.sinaimg.cn/large/008i3skNgy1gyfz2tvz1oj315e0s4wgv.jpg)

  - 括号匹配：我们用栈来保存未匹配的左括号
    - 从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。
    - 如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。
    - 当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。
  - 浏览器的前进与后退：我们使用两个栈，X和Y，
    - 我们把首次浏览的页面依次压入栈X，
    - 当点击后退按钮时，再依次从栈X中出栈，并将出栈的数据依次放入栈Y。
    - 当我们点击前进按钮时，我们依次从栈Y中取出数据，放入栈X中。
    - 当栈X中没有数据时，那就说明没有页面可以继续后退浏览了。当栈Y中没有数据，那就说明没有页面可以点击前进按钮浏览了。

## 队列

- 最基本的操作也是两个：**入队enqueue()**，放一个数据到队列尾部；**出队dequeue()**，从队列头部取一个元素。
- 可以用数组，也可以用链表实现丢咧，用数组实现的叫顺序队列，用链表实现的叫链式队列
- 应用广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。
- 它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列Disruptor、Linux环形缓存，都用到了循环并发队列；Java concurrent并发包利用ArrayBlockingQueue来实现公平锁等

- 循环队列，实现起来最关键是**确定好队空和队满的判定条件**。
  - 队列为空的判断条件仍然是head == tail
  - 队列为满的判断条件是**(tail+1)%n=head**，tail指向的位置没有存放数据，所以会浪费一个元素的数组空间

- **阻塞队列**其实就是在队列基础上增加了阻塞操作，阻塞队列可以轻松实现生产者-消费者模型。

  - 简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；

  - 如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

- **并发队列**是线程安全的队列。
  - 最简单直接的实现方式是直接在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。
  - 实际上，基于数组的循环队列，利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因

- 队列可以解决在线程池等有限资源场景的问题
  - 非阻塞方式可以在队列为空时直接拒绝请求，阻塞队列可以将请求排队，等资源空闲时再取出来回应请求
  - 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。
  - 而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。

## 递归

- 三个条件

  **1.一个问题的解可以分解为几个子问题的解**

  **2.这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样**

  **3.存在递归终止条件**

- 很多时候，递归理解的难点在于人脑习惯平铺直叙，习惯把递归展开，实际上，我们考虑问题A可以分为子问题B、C、D后，可以直接认为B、C、D已经解决了，只需考虑A与B、C、D的关系即可
- **编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤**。

- 递归代码要注意堆栈溢出，因为函数栈是需要内存空间的
- 递归代码要警惕重复计算，比如可以用散列表存储已经计算过的函数值
- 递归需要额外的空间，所以空间复杂度不能忽略

## 排序

- 执行效率
  - 排序算法要考虑最好、最坏、平均时间复杂度，因为待排序数据可能是接近无序或接近有序，
  - 时间复杂度反映的是数据规模n很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但是实际的软件开发中，我们排序的可能是10个、100个、1000个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来。
  - 基于比较的排序算法的执行过程，会涉及两种操作，一种是元素比较大小，另一种是元素交换或移动。所以，如果我们在分析排序算法的执行效率的时候，应该把比较次数和交换（或移动）次数也考虑进去。

- 内存消耗
  - 原地排序算法，就是特指空间复杂度是O(1)的排序算法
- 是否稳定
  - 稳定性：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。
  - **稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变**
  - 实际开发中，我们可能是对键值对中的键进行排序，值是否保序也是我们关注的点

### 冒泡排序（Bubble Sort）

- 冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复n次，就完成了n个数据的排序工作。

- 优化：当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作

  ```java
  // 冒泡排序，a表示数组，n表示数组大小
  public void bubbleSort(int[] a, int n) {
    if (n <= 1) return;
   
   for (int i = 0; i < n; ++i) {
      // 提前退出冒泡循环的标志位
      boolean flag = false;
      for (int j = 0; j < n - i - 1; ++j) {
        if (a[j] > a[j+1]) { // 交换
          int tmp = a[j];
          a[j] = a[j+1];
          a[j+1] = tmp;
          flag = true;  // 表示有数据交换      
        }
      }
      if (!flag) break;  // 没有数据交换，提前退出
    }
  }
  ```

- 原地排序

- 稳定（当前后两个元素大小一样时不做交换即可实现稳定）

- 最好时间复杂度：O(1)（有序时，只需要一次冒泡即可完成）

- 最坏时间复杂度：O(n^2)（完全倒序时，需要n次冒泡）

- **有序度**是数组中具有有序关系的元素对的个数，完全有序的数组的有序度叫作**满有序度**，**逆序度=满有序度-有序度**

  - 有序元素对：a[i] <= a[j], 如果i < j
  - 对于一个倒序排列的数组，比如6，5，4，3，2，1，有序度是0；对于一个完全有序的数组，比如1，2，3，4，5，6，有序度就是**n\*(n-1)/2**，也就是15

- 平均时间复杂度：O(n^2)

### 插入排序（Insertion Sort）

- 首先，我们将数组中的数据分为两个区间，**已排序区间**和**未排序区间**。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。

  ![image-20220119000023901](https://tva1.sinaimg.cn/large/008i3skNly1gyi9pwfvv9j30s60pujti.jpg)

- 插入排序也包含两种操作，一种是**元素的比较**，一种是**元素的移动**。当我们需要将一个数据a插入到已排序区间时，需要拿a与已排序区间的元素依次比较大小，找到合适的插入位置。找到插入点之后，我们还需要将插入点之后的元素顺序往后移动一位，这样才能腾出位置给元素a插入。

- 移动操作的次数总是固定的，就等于逆序度

  ```java
  // 插入排序，a表示数组，n表示数组大小
  public void insertionSort(int[] a, int n) {
    if (n <= 1) return;
  
    for (int i = 1; i < n; ++i) {
      int value = a[i];
      int j = i - 1;
      // 查找插入的位置
      for (; j >= 0; --j) {
        if (a[j] > value) {
          a[j+1] = a[j];  // 数据移动
        } else {
          break;
        }
      }
      a[j+1] = value; // 插入数据
    }
  }
  
  ```

- 原地排序

- 稳定（对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，即可实现稳定

- 最好时间复杂度：O(n)，**从尾到头遍历已经有序的数据**时才能实现

- 最坏时间复杂度：O(n^2)，如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据

- 平均时间复杂度：O(n^2)，在数组中插入一个数据的平均时间复杂度是O(n)，要插入n次，所以是O(n^2)

- 插入排序与冒泡排序的时间复杂度一样，元素交换的次数都等于原始数据的逆序度，**但是插入排序只需要一次数据移动操作，冒泡操作**（见代码）

### 选择排序（Selection Sort）

- 选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。

- 已排序区间的末尾是待排序的第一个，所以会交换

  ![image-20220118235546819](https://tva1.sinaimg.cn/large/008i3skNly1gyi9l56mg0j31330u0n0c.jpg)

- 原地排序
- 最好、最坏、平均时间复杂度都是O(n^2)
- **不稳定**，因为会交换，破坏了稳定性

### 归并排序（MergeSort）

- 如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了

- **分治思想**，一般用递归实现

  ```
  // 归并排序算法, A是数组，n表示数组大小
  merge_sort(A, n) {
    merge_sort_c(A, 0, n-1)
  }
  
  // 递归调用函数
  merge_sort_c(A, p, r) {
    // 递归终止条件
    if p >= r  then return
  
    // 取p到r之间的中间位置q
    q = (p+r) / 2
    // 分治递归
    merge_sort_c(A, p, q)
    merge_sort_c(A, q+1, r)
    // 将A[p...q]和A[q+1...r]合并为A[p...r]
    merge(A[p...r], A[p...q], A[q+1...r])
  }
  ```

- merge函数的过程如图所示

  ![image-20220119000510869](https://tva1.sinaimg.cn/large/008i3skNly1gyi9uvftmwj31380u0tcj.jpg)

  - 我们申请一个临时数组tmp，大小与A[p...r]相同。我们用两个游标i和j，分别指向A[p...q]和A[q+1...r]的第一个元素。比较这两个元素A[i]和A[j]，如果A[i]<=A[j]，我们就把A[i]放入到临时数组tmp，并且i后移一位，否则将A[j]放入到数组tmp，j后移一位。

  - 继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的末尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组tmp中的数据拷贝到原数组A[p...r]中。

    ```
    merge(A[p...r], A[p...q], A[q+1...r]) {
      var i := p，j := q+1，k := 0 // 初始化变量i, j, k
      var tmp := new array[0...r-p] // 申请一个大小跟A[p...r]一样的临时数组
      while i<=q AND j<=r do {
        if A[i] <= A[j] {
          tmp[k++] = A[i++] // i++等于i:=i+1
        } else {
          tmp[k++] = A[j++]
        }
      }
      
      // 判断哪个子数组中有剩余的数据
      var start := i，end := q
      if j<=r then start := j, end:=r
      
      // 将剩余的数据拷贝到临时数组tmp
      while start <= end do {
        tmp[k++] = A[start++]
      }
      
      // 将tmp中的数组拷贝回A[p...r]
      for i:=0 to r-p do {
        A[p+i] = tmp[i]
      }
    }
    ```

- 稳定：如果A[p...q]和A[q+1...r]之间有值相同的元素，那我们可以像伪代码中那样，先把A[p...q]中的元素放入tmp数组。这样就保证了值相同的元素，在合并前后的先后顺序不变

- 不是原地排序，需要O(n)的额外空间存放临时数组（所以应用不如快排广泛

- 递归的时间复杂度分析

  - 假设问题a可以分解为b与c，b与c解决后，再把b、c的结果合并成a的结果，则T(a) = T(b) + T(c) +K
  - **不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式。**

- 假设对n个元素进行归并排序需要的时间是T(n)，两个子数组排序的时间都是T(n/2)，merge()函数合并两个有序子数组的时间复杂度是O(n)，

  ```
  T(n) = 2*T(n/2) + n
       = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
       = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
       = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
       ......
       = 2^k * T(n/2^k) + k * n
       ......
  ```

- 当T(n/2^k)=T(1)时，也就是n/2^k=1，故T(n)=O(nlogn)，所以归并排序的时间复杂度是O(nlogn)。最好、最坏、平均都是

### 快速排序（QuickSort）

- 从排序数组中下标从p到r之间选择任意一个数据作为pivot（分区点）

- 我们遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的，中间是pivot，后面的q+1到r之间是大于pivot的。

- 根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。

  ```
  // 快速排序，A是数组，n表示数组的大小
  quick_sort(A, n) {
    quick_sort_c(A, 0, n-1)
  }
  // 快速排序递归函数，p,r为下标
  quick_sort_c(A, p, r) {
    if p >= r then return
    
    q = partition(A, p, r) // 获取分区点
    quick_sort_c(A, p, q-1)
    quick_sort_c(A, q+1, r)
  }
  ```

- partition()分区函数可以很简单，随机选择一个元素作为pivot（一般可以选择p到r区间的最后一个元素），然后额外申请两个临时数组，数组p到r区间中小于pivot的元素放第一个数组，大于的放第二个数组，但是这样需要很多额外空间，不是原地排序

- 原地排序的分区函数实现如下

  ```
  partition(A, p, r) {
    pivot := A[r] // 选择最后一个元素作为pivot
    i := p
    for j := p to r-1 do {
      if A[j] < pivot {
        swap A[i] with A[j]
        i := i+1
      }
    }
    swap A[i] with A[r]
    return i
  ```

  - 这里的处理有点类似选择排序。我们通过游标i把A[p...r-1]分成两部分。A[p...i-1]的元素都是小于pivot的，我们暂且叫它“已处理区间”，A[i...r-1]是“未处理区间”。我们每次都从未处理的区间A[i...r-1]中取一个元素A[j]，与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部，也就是A[i]的位置。

  - 交换，在O(1)的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将A[i]与A[j]交换，就可以在O(1)时间复杂度内将A[j]放到下标为i的位置。

  ![image-20220119002248240](https://tva1.sinaimg.cn/large/008i3skNly1gyiad7nol2j30z30u0ju5.jpg)

- 不稳定，因为有交换
- 最好时间复杂度：每次分区如果能把数组分成大小接近的两个子区间，那么快排的时间复杂度与归并排序类似，都是O(nlogn），可以通过合理选择pivot从而保证大部分时间都是O(nlogn)
  - 三数取中法：我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这3个数的中间值作为分区点。但当排序的数组比较大，那可能要五数取中、十数取中了
  - 随机法：从概率来看，平均的时间复杂度也比较好
- 最坏时间复杂度：分区极不均匀，退化成O(n^2)，但只有在极端情况才会出现

- 归并排序vs快排：归并排序的处理过程是**由下到上**的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是**由上到下**的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为O(nlogn)的排序算法，但是它是非原地排序算法
- 快排用递归实现，要警惕堆栈溢出，可以设置堆栈阈值，超过则终止递归，也可以用栈来手动模拟递归
- 快排可以解决TopK问题

### 桶排序（Bucket sort）

- 核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。
- 如果要排序的数据有n个，我们把它们均匀地划分到m个桶内，每个桶里就有k=n/m个元素。每个桶内部使用快速排序，时间复杂度为O(k * logk)。m个桶排序的时间复杂度就是O(m * k * logk)，因为k=n/m，所以整个桶排序的时间复杂度就是O(n*log(n/m))。当桶的个数m接近数据个数n时，log(n/m)就是一个非常小的常量，这个时候桶排序的时间复杂度接近O(n)。
- 苛刻的适用场景：能轻易划分到桶、桶有天然的大小顺序、数据在各个桶中比较均匀（极端场景是所有数据都在一个桶中，就退化成了O(nlogn)）
- **桶排序比较适合用在外部排序中**。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。
- 可以解决给一群人的年龄排序、给高考成绩排序

### 计数排序（Counting sort）

- 我个人觉得，**计数排序其实是桶排序的一种特殊情况**。当要排序的n个数据，所处的范围并不大的时候，比如最大值是k，我们就可以把数据划分成k个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

- 似乎计数排序与桶排序的差别仅在桶的粒度上，但是可以借助另一个数组来巧妙实现排序
- **计数排序只能用在数据范围不大的场景中，如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。**

### 基数排序（Radix sort）

- 将数字按照个位数开始排序，然后再按照十位数来排序，以此类推
- 注意，这里按照每位来排序的排序算法要是稳定的，否则这个实现思路就是不正确的。因为如果是非稳定排序算法，那最后一次排序只会考虑最高位的大小顺序，完全不管其他位的大小关系，那么低位的排序就完全没有意义了。
- 根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到O(n)。如果要排序的数据有k位，那我们就需要k次桶排序或者计数排序，总的时间复杂度是O(k*n)

- **基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果a数据的高位比b数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到O(n)了**。

- 可以解决给电话号码排序的问题

- 假设我们现在需要对D，a，F，B，c，A，z这个字符串进行排序，要求将其中所有小写字母都排在大写字母的前面，但小写字母内部和大写字母内部不要求有序。比如经过排序之后为a，c，z，D，F，B，A，这个如何来实现呢？如果字符串中存储的不仅有大小写字母，还有数字。要将小写字母的放到前面，大写字母放在最后，数字放在中间，不用排序算法，又该怎么解决呢？

  将D，a，F，B，c，A，z转换成ASCII码。小于等于90的为第一组（大写字母）。大于等于97的为第二组（小写字母），最后第二组数据append到第一组以后即可。数字亦同理

### 排序优化

- Java语言采用堆排序实现排序函数，C语言使用快速排序实现排序函数。

- 归并排序因为不是原地排序，所以用的地方并不多

- **Glibc的qsort()**

  - **优先使用归并排序来排序输入数据**，空间换时间

  - **排序的数据量比较大的时候，qsort()会改为用快速排序算法来排序**

  - 三数取中法选择pivot

  - 手动模拟递归，防止堆栈溢出

  - 当要排序的区间中，元素的个数小于等于4时，qsort()就退化为插入排序

    > 在小规模数据面前，**O(n****2****)时间复杂度的算法并不一定比O(nlogn)的算法执行时间长**

### 二分查找

- **二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为0**。

- 时间复杂度就是O(logn)

  > O(logn)这种**对数时间复杂度**有时效率比O(1)还高！因为logn可以快速缩小数量级

- 十个二分九个错，容易理解的写法才是最好的，不用可以追求优雅简洁

- **最简单的情况**就是**有序数组中不存在重复元素**

  ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
  
    while (low <= high) {
      int mid = (low + high) / 2;
      if (a[mid] == value) {
        return mid;
      } else if (a[mid] < value) {
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
  
    return -1;
  }
  
  // 二分查找的递归实现
  public int bsearch(int[] a, int n, int val) {
    return bsearchInternally(a, 0, n - 1, val);
  }
  
  private int bsearchInternally(int[] a, int low, int high, int value) {
    if (low > high) return -1;
  
    int mid =  low + ((high - low) >> 1);
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      return bsearchInternally(a, mid+1, high, value);
    } else {
      return bsearchInternally(a, low, mid-1, value);
    }
  }
  
  ```

- 容易出错的三个地方：

  - 循环退出条件，注意是low<=high
  - mid的取值，mid=(low+high)/2有可能溢出，改成low+(high-low)/2，追求性能的话，可以用low+((high-low)>>1)
  - low和high的更新，low=mid+1，high=mid-1

- 二分法局限
  - 必须是顺序表结构，即数组，链表不支持随机下标访问，所以不能用二分法
  - 只能查有序数据，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中
  - **数据量太小不适合二分查找。**直接遍历即可
  - **最后，数据量太大也不适合二分查找。**为了支持随机访问，要求内存空间连续，太大的数据用数组存储就比较吃力了，也就不能用二分查找了

- 查找第一个值等于给定值的元素

  - 如果mid等于0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；
  - 如果mid不等于0，但a[mid]的前一个元素a[mid-1]不等于value，那也说明a[mid]就是我们要找的第一个值等于给定值的元素。
  - 如果经过检查之后发现a[mid]前面的一个元素a[mid-1]也等于value，那说明此时的a[mid]肯定不是我们要查找的第一个值等于给定值的元素。那我们就更新high=mid-1，因为要找的元素肯定出现在[low, mid-1]之间。

  ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
    while (low <= high) {
      int mid =  low + ((high - low) >> 1);
      if (a[mid] > value) {
        high = mid - 1;
      } else if (a[mid] < value) {
        low = mid + 1;
      } else {
        if ((mid == 0) || (a[mid - 1] != value)) return mid;
        else high = mid - 1;
      }
    }
    return -1;
  }
  ```

- 查找最后一个值等于给定值的元素

  - 如果a[mid]这个元素已经是数组中的最后一个元素了，那它肯定是我们要找的；
  - 如果a[mid]的后一个元素a[mid+1]不等于value，那也说明a[mid]就是我们要找的最后一个值等于给定值的元素。
  - 如果我们经过检查之后，发现a[mid]后面的一个元素a[mid+1]也等于value，那说明当前的这个a[mid]并不是最后一个值等于给定值的元素。我们就更新low=mid+1，因为要找的元素肯定出现在[mid+1, high]之间。

  ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
    while (low <= high) {
      int mid =  low + ((high - low) >> 1);
      if (a[mid] > value) {
        high = mid - 1;
      } else if (a[mid] < value) {
        low = mid + 1;
      } else {
        if ((mid == n - 1) || (a[mid + 1] != value)) return mid;
        else low = mid + 1;
      }
    }
    return -1;
  }
  ```

- 查找第一个大于等于给定值的元素

  ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
    while (low <= high) {
      int mid =  low + ((high - low) >> 1);
      if (a[mid] >= value) {
        if ((mid == 0) || (a[mid - 1] < value)) return mid;
        else high = mid - 1;
      } else {
        low = mid + 1;
      }
    }
    return -1;
  }
  ```

- 查找最后一个小于等于给定值的元素

  ```java
  public int bsearch7(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
    while (low <= high) {
      int mid =  low + ((high - low) >> 1);
      if (a[mid] > value) {
        high = mid - 1;
      } else {
        if ((mid == n - 1) || (a[mid + 1] > value)) return mid;
        else low = mid + 1;
      }
    }
    return -1;
  }
  ```

  
