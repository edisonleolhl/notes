# 数据结构与算法之美

- 数据结构和算法是相辅相成的。**数据结构是为算法服务的，算法要作用在特定的数据结构之上**

- 想要学习数据结构与算法，**首先要掌握一个数据结构与算法中最重要的概念——复杂度分析。**
- 王争总结的最常用、最基础的20个数据结构与算法
  - 10个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树；
  - 10个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

## 复杂度分析

- 规律：**所有代码的执行时间T(n)与每行代码的执行次数f(n)成正比**。
- **大O时间复杂度表示法**：T(n)=O(f(n))
  - T(n)我们已经讲过了，它表示代码执行的时间；
  - n表示数据规模的大小；
  - f(n)表示每行代码执行的次数总和。
  - 公式中的O，表示代码的执行时间T(n)与f(n)表达式成正比。

- 大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。大O表示法通常会忽略掉公式中的常量、低阶、系数

- **加法法则：总复杂度等于量级最大的那段代码的复杂度**

- **乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积**

- **多项式量级**和**非多项式量级**。其中，非多项式量级只有两个：O(2n)和O(n!)。

  > 我们把时间复杂度为非多项式量级的算法问题叫作NP（Non-Deterministic Polynomial，非确定多项式）问题。

- 常见时间复杂度

  - O(1)：**一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)**

  - O(log2(n))：O(log3(n))也可以转换为O(log2(n))，因为log3(n)就等于log3(2) * log2(n)，log3(2)是常数系数，可以省略

    ```c++
    // 示例
    i=1;
     while (i <= n)  {
       i = i * 3;
     }
    ```

  - O(n*log2(n))：乘法法则，加一层n的嵌套，也很常见，比如归并排序、快速排序的时间复杂度都是O(nlogn)

  - **O(m+n)、O(m\*n)**：**由两个数据的规模**来决定，m和n是表示两个数据规模。我们无法事先评估m和n谁的量级大

- **最好情况时间复杂度**（best case time complexity）、**最坏情况时间复杂度**（worst case time complexity）
- **平均情况时间复杂度**（average case time complexity）：可能需要概率论的知识，但在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况，只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。
- **均摊时间复杂度**（amortized time complexity）：比平均时间复杂度更特殊，**摊还分析法**：每一次O(n)的插入操作，都会跟着n-1次O(1)的插入操作，所以把耗时多的那次操作均摊到接下来的n-1次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是O(1)

## 数组

- **数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据**

  > 除了数组，链表、队列、栈等也是线性表结构

- 高级语言一般提供了容器了代替数组，但数组在以下场景还是有用武之地的：
  - 1.Java ArrayList无法存储基本类型，比如int、long，需要封装为Integer、Long类，而Autoboxing、Unboxing则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
  - 2.如果数据大小事先已知，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以直接使用数组。
  - 3.还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如Object[][] array；而用容器的话则需要这样定义：`ArrayList<ArrayList > array

- 对于业务开发，直接使用容器就足够了，但是如果是底层开发，需要极致性能，数组会更优，当然debug难度也会更大

- 为什么数组要从0开始编号？

  - “下标”最确切的定义应该是“偏移（offset）”。如果用a来表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址

    > ```c
    > // a[k]的内存地址计算公式
    > a[k]_address = base_address + k * type_size
    > // 二维数组的内存地址计算公式
    > a[x][y]_address = base_address + (y * x_array_length(X轴长度) + x) * data_type_size
    > 
    > ```

  - 后面出现的编程语言效仿C语言，也都用0作为下表了，但是Matlab是从1开始的，Python甚至还支持负数下标

## 链表

- LinkedHashMap就是使用的双向链表
- **用空间换时间**，双向链表虽然比单链表每个节点都多了一个前驱指针，但是查找与删除操作更加灵活
- 链表vs数组
  - 数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对CPU缓存不友好，没办法有效预读。
  - 数组的缺点是大小固定，一经声明就要占用整块连续内存空间，链表天然就支持扩容
  - 如果你的代码对内存的使用非常苛刻，那数组就更适合你，因为链表需要额外的空间存储指针

- 缓存淘汰算法，常见的策略有三种：先进先出策略FIFO（First In，First Out）、最少使用策略LFU（Least Frequently Used）、最近最少使用策略LRU（Least Recently Used）

- 有序单链表就可以实现LRU，当有一个新的数据被访问时，我们从链表头开始顺序遍历链表（因为这个操作，所以时间复杂度为O(n)）。

  1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。

  2. 如果此数据没有在缓存链表中，又可以分为两种情况：

     - 如果此时缓存未满，则将此结点直接插入到链表的头部；

     - 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

  3. 引入**散列表**（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到O(1)

- 如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？

  1、通过快慢指针定位中间节点

  2、对后半部分链表逆序

  3、前后链表对比，判断是否为回文串

  4、恢复后半部分链表顺序

  时间复杂度O(n)、空间复杂度O(1)

- 写链表代码的技巧

  - 理解指针或引用的含义，p->next=q，p结点中的next指针存储了q结点的内存地址。

  - 警惕指针丢失和内存泄漏，**插入结点时，一定要注意操作的顺序**，**删除链表结点时，也一定要记得手动释放内存空间**，

  - 利用哨兵简化实现难度，**针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理**，在任何时候，不管链表是不是空，head指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫**带头链表**。相反，没有哨兵结点的链表就叫作**不带头链表**。

  - 重点留意边界条件处理

    - 如果链表为空时，代码是否能正常工作？

    - 如果链表只包含一个结点时，代码是否能正常工作？

    - 如果链表只包含两个结点时，代码是否能正常工作？

    - 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

  - 举例画图，辅助思考

  - 多写多练，没有捷径

    - 单链表反转

    - 链表中环的检测

    - 两个有序的链表合并

    - 删除链表倒数第n个结点

    - 求链表的中间结点

## 栈

- 栈只支持两个基本操作：**入栈push()和出栈pop()**
- 从功能上来说，数组或链表确实可以替代栈，但是数组或链表暴露了太多操作接口，操作比较不可控，容易出错
- 复习一下均摊分析法，动态扩容的数组/栈，k-1次插入操作都是O(1)，然后来一次顺序搬迁需要O(n)，但是均摊到前面k-1次O(1)的操作上，所以摊还分析时间复杂度仍然是O(1)

- 应用

  - 函数栈

  - 表达式求值，一个栈保存操作数，一个栈保存运算符

    - 如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；
    - 如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取2个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

    ![image-20220117002103552](https://tva1.sinaimg.cn/large/008i3skNgy1gyfz2tvz1oj315e0s4wgv.jpg)

  - 括号匹配：我们用栈来保存未匹配的左括号
    - 从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。
    - 如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。
    - 当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。
  - 浏览器的前进与后退：我们使用两个栈，X和Y，
    - 我们把首次浏览的页面依次压入栈X，
    - 当点击后退按钮时，再依次从栈X中出栈，并将出栈的数据依次放入栈Y。
    - 当我们点击前进按钮时，我们依次从栈Y中取出数据，放入栈X中。
    - 当栈X中没有数据时，那就说明没有页面可以继续后退浏览了。当栈Y中没有数据，那就说明没有页面可以点击前进按钮浏览了。

## 队列

- 最基本的操作也是两个：**入队enqueue()**，放一个数据到队列尾部；**出队dequeue()**，从队列头部取一个元素。
- 可以用数组，也可以用链表实现丢咧，用数组实现的叫顺序队列，用链表实现的叫链式队列
- 应用广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。
- 它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列Disruptor、Linux环形缓存，都用到了循环并发队列；Java concurrent并发包利用ArrayBlockingQueue来实现公平锁等

- 循环队列，实现起来最关键是**确定好队空和队满的判定条件**。
  - 队列为空的判断条件仍然是head == tail
  - 队列为满的判断条件是**(tail+1)%n=head**，tail指向的位置没有存放数据，所以会浪费一个元素的数组空间

- **阻塞队列**其实就是在队列基础上增加了阻塞操作，阻塞队列可以轻松实现生产者-消费者模型。

  - 简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；

  - 如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

- **并发队列**是线程安全的队列。
  - 最简单直接的实现方式是直接在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。
  - 实际上，基于数组的循环队列，利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因

- 队列可以解决在线程池等有限资源场景的问题
  - 非阻塞方式可以在队列为空时直接拒绝请求，阻塞队列可以将请求排队，等资源空闲时再取出来回应请求
  - 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。
  - 而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。

## 递归

- 三个条件

  **1.一个问题的解可以分解为几个子问题的解**

  **2.这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样**

  **3.存在递归终止条件**

- 很多时候，递归理解的难点在于人脑习惯平铺直叙，习惯把递归展开，实际上，我们考虑问题A可以分为子问题B、C、D后，可以直接认为B、C、D已经解决了，只需考虑A与B、C、D的关系即可
- **编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤**。

- 递归代码要注意堆栈溢出，因为函数栈是需要内存空间的
- 递归代码要警惕重复计算，比如可以用散列表存储已经计算过的函数值
- 递归需要额外的空间，所以空间复杂度不能忽略

